+++
title = 'mysql连接数激增的问题解决过程'
date = 2023-12-30T21:32:00+08:00
draft = false
+++
> 平时mysql连接数大概在2000左右,会不定时随机的突然增加到5000,这个事情就很恐怖,所以需要查出来连接数增加的原因

## 分析与定位问题 {#%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9A%E4%BD%8D%E9%97%AE%E9%A2%98 tabindex="-1"}

### 分析现有的监控和数据 {#%E5%88%86%E6%9E%90%E7%8E%B0%E6%9C%89%E7%9A%84%E7%9B%91%E6%8E%A7%E5%92%8C%E6%95%B0%E6%8D%AE tabindex="-1"}

1.  连接数 5000的报警钉钉信息
2.  当连接数5000的时候,数据库里当前连接正在执行的状态

``` {.hljs .language-perl}
    SELECT  `id`,`user`,`host`,`db`,`command`,`time`,`state`,`info` FROM information_schema.processlist
```

分析第二个的数据,看到连接基本都在sleep,很少有正在执行的,由于连接数据库是通过内网代理连接的,所以不能直接看出来哪个或者哪些机器导致了这个问题

### 增加新的监控 {#%E5%A2%9E%E5%8A%A0%E6%96%B0%E7%9A%84%E7%9B%91%E6%8E%A7 tabindex="-1"}

要定位哪里的问题就需要知道哪个程序或者哪个机器导致的,一步一步深入查,现在连哪个机器导致的问题都不知道,没办法去查,幸运的是这个问题是可以重现的,不必纠结过去没有数据,创造出新的数据再定位问题就行.\
在这里就想到了`netstat`{.language-plaintext
.highlighter-rouge}命令,这个可以在代理机器上执行,查看哪些IP连接了mysql代理服务,并统计个数,于是就把这个命令的触发加到了发送钉钉报警的程序里.\
到这里又想到了一个问题,异常数据有了之后,没有正常的数据做对比还是定位不出来问题,所以增加了每分钟执行一次来保存正常数据用于做对比.

### 分析新监控数据 {#%E5%88%86%E6%9E%90%E6%96%B0%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE tabindex="-1"}

等了1天终于等到了这个报警出现,对比平时的数据来说按连接数倒序,可以看到前边的大多数ip连接数都增加了,问了一下运维这些机器上都有哪些服务,被告知都是线上的tomcat服务.\
到这里总算有了一些进展,但是到了这里又遇到问题了,tomcat里边虽然只有一个项目,但是这个项目中代码量很大,review代码是看不出来也没有办法都review一遍,有什么办法可以定位什么业务创建了连接呢?\
之前读过一遍arthas的文档,对大概的命令以及功能有所了解,于是就想到了
[stack](https://arthas.aliyun.com/doc/stack.html){target="_blank"} 这个命令,这个命令可以打印当前方法的调用堆栈信息,因为创建连接是必须new对象,那么监控这个new对象时候必须调用的方法就可以定位到具体的代码.\
因为这个是随机性的bug,那么靠人手动执行是看不出问题的,于是使用了arthas提供的任务后台执行的方法,后台任务最多执行1天,同时需要指定抓取多少条堆栈信息.\
之前没用过arthas,只是看文档知道执行stack会影响性能,但是具体影响多少性能并不清楚,这里找了一台线上tomcat手动执行stack,并观察了超时情况,超时只增加了0.5%,这个值可以接受,于是就开始后台执行了

### 等待新的监控数据 {#%E7%AD%89%E5%BE%85%E6%96%B0%E7%9A%84%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE tabindex="-1"}

等啊等,终于等到了报警,查看对应时间的连接创建堆栈信息,问题出在缓存读取的方法上.\
如果缓存没有就会读取数据库,同一时间突然有很多都去查询数据库了,原因是缓存里没有对应的数据了,缓存是一个concurrenthashmap,直接做的替换,而同时这个map会根据实际情况增加数据进入,由此可以判断是新加的那部分数据,缓存替换的时候消失了.

### 思考解决方案 {#%E6%80%9D%E8%80%83%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88 tabindex="-1"}

缓存直接做替换是不行的,会丢失新加入的数据,那首先想到的是更新数据,更新数据会有一个问题是按之前逻辑新增加的那部分数据就会一直存在,内存也会越占用越多,所以需要有删除过期数据的程序,那么问题又来了,这个不好写,就算写了也不好维护.\
这里就想到了**Caffeine缓存框架**,当真是很强大的本地内存缓存的框架,可以设置多久没有访问就会过期,也支持更新操作,对于我这个需求来说简直完美.\
到了这里这个问题就算解决了,修改代码不过半小时的事情,主要的问题还是如何定位出来哪里代码有问题,
